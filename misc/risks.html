<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>COMP501 0613 Assignment 3 Risks</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
<!--<img src="../images/csg4ed-small.png" alt="Enhancing Social Good in Computing"-->


<!-- Top Heading -->

<h1 class="title">ChatGPT : Impact on Student Academics</h1>

<h2 class="title">Group 0613 COMP501 Assigment 3</h2>



<!-- Site navigation menu -->

<ul class="navbar">
	<li><a href="../index.html">Home Page</a>
    <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="risks.html">Risks</a>
	<li><a href="choices.html">Choices</a>
	<li><a href="references.html">References</a>
	<li><a href="process.html">Process Support</a>
</ul>



<!-- Main content -->

<h1>Technology Risks</h1>

<h2>Overview</h2>
<p>Although AI tools have the potential to benefit both learners and teachers, they may also carry risks,
 such as academic misconduct alongside unjust advantages for end-users and the possibility of privacy violations.</p><br>
 
 <!-- Diminished Learning Outcomes -->
 
 <h2>Diminished Learning Outcomes</h2>
 <p>One of the first risks that the use of ChatGPT in education could bring is diminished learning for students
 and an overreliance on technology.</p> 
 
 <p>Having the opportunity to use ChatGPT to make learning subjects easier for 
 students is helpful, but relying too heavily on this AI tool can have significant impacts on the way the student 
 continues to learn and their skills. "The main challenge that students face is the illusion of explanatory, which 
 refers to the belief that students think that they have a complete understanding of a particular topic while they 
 actually have a shallow understanding" (Tajik & University of California, Irvine, 2023). The “illusion of 
 explanatory" arises when students rely too heavily on ChatGPT for their learning. This can hinder the students' 
 development of how they understand the subject, which can then lead to gaps in their knowledge and misunderstandings.</p>
 
 <p>Varwandkar (2023) supports this statement as they also point out that “If students become overly reliant on Chat GPT, 
 their independent critical thinking and problem-solving skills may deteriorate”. As well as this, Mishra and Awasthi 
 (2023) state that “because ChatGPT replies are produced by computers rather than people, it raises questions about 
 the authenticity and integrity of human communication”.</p> 
 
 <p>When students rely too heavily on ChatGPT to assist them 
 with their educational journey, they lose the ability to critically think for themselves and develop a thorough 
 understanding of the subject. As well as this, it also means the students might not actively engage in critical 
 thinking and problem solving, which are both essential skills to have in the wider world. By relying heavily on 
 ChatGPT for all aspects of their learning, it may limit their ability to participate in discussions, debates, and 
 collaborative activities, which are essential for developing the previously mentioned and necessary social skills.</p><br>



 <!-- Academic Misconduct -->
 
<h2>Academic Misconduct</h2>
<p>Another risk that the use of ChatGPT in education poses is academic dishonesty and unfair advantages.</p>

<p>Cheating in tests and assignments has been happening for decades, and with the new AI tools easily accessible 
for most students, it has become much easier for students to do so. Cotton et al. (2023) state that “students 
could potentially use these systems to cheat on their assignments by submitting essays that are not their own 
work”. They also go on to state that “this undermines the very purpose of higher education, which is to challenge 
and educate students, and could ultimately lead to a devaluation of degrees”. This high potential for students to 
use ChatGPT in a dishonest way not only reduces the fairness within the educational system, but it also takes away 
the learning experience from students. As a result, there may be less trust within the system, which may make it 
more difficult for teachers to evaluate students' skills and knowledge. The University of Missouri (ChatGPT, 
Artificial Intelligence, and Academic Integrity, 2023) points out that “Students who use ChatGPT and similar 
programs improperly are seeking to gain an unfair advantage, which means they are committing academic dishonesty”.</p>

<p>The worrying possibility that "students may possibly use ChatGPT to complete essay-type assignments without 
getting caught" is also emphasised by Khalil and Er’s findings within their research (2023). The integrity of 
the educational process is further compromised by this finding, which highlights how students can easily use 
AI tools dishonestly during their education.</p>

<p>Furthermore, the amount of academic dishonesty and unfair advantages 
given by ChatGPT removes the purpose of higher education, which is to challenge students and educate them thoroughly. 
Like Cotton et al. (2023) suggest, this could lead to the “devaluation of degrees” as authenticity among students 
decreases. </p>

<p>As well as this, many students don’t have full access to technology, including ChatGPT. This creates an 
unfair advantage among students, as those who do have access may have better quality and depth in their work.</p><br>



 <!-- Privacy and Data Security -->
<h2>Privacy and Data Security</h2>
<p>The final large risk that the use of ChatGPT in education brings is privacy and data security.</p>

<p>As the use of AI tools becomes normal in the daily lives of students, it is important to consider what information 
may be collected. When engaging with ChatGPT, users' interactions and information may be collected and stored within 
the system. This can be concerning when we think about how this data is handled and controlled, apart from what is 
used within the chat.</p>

<p>As many students are not fully educated on the risks of giving out personal information online, like primary and 
secondary students, having measures in place to protect the user's privacy from unauthorised access or misuse.</p>

<p>One main concern is the potential for data breaches. If the security measures created by OpenAI - the developers 
of ChatGPT - are compromised, it could lead to the private information of its users being exposed. As stated in OpenAI’s 
privacy policy, they “may collect Personal Information that is included in the input, file uploads, or feedback that you 
provide to our Services”. The likelihood of data breaches is high, just like with any other online service.</p>

<p>To lessen the likelihood of this, OpenAI has put in place a number of strong security measures. These include encryption, 
access controls, external security audits, a “bug bounty program”, and incident response plans (Experts, 2023b). In a study 
done by Li et al. (2023), they concluded that in an attempt to extract private information, “ChatGPT of the Mar Version 
tends to hesitate from answering any private information if we use direct prompts for data extraction”. The continuous 
strive to increase and improve the security of private information is important to ensure that the risk of a data breach 
is addressed. By prioritising user privacy and adhering to strict security protocols, OpenAI provides a safe platform for 
learners to engage with its AI technology.</p><br>


<!-- Sign and date the page, it's only polite! -->
<address>Made June 8 2023<br>
  by Group 0613.</address>
  
 </html>